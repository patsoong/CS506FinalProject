{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIEGcKxNxupF98cNLZKWNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patsoong/CS506FinalProject/blob/main/notebooks/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlrLGHM_0RHF",
        "outputId": "6bb8fd4d-2077-47c0-a20f-9fef04cabe9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
            "Best parameters: {'clf__estimator__C': 1, 'clf__estimator__class_weight': 'balanced', 'clf__estimator__gamma': 0.01}\n",
            "SVM ROC-AUC: 0.9717241379310345\n",
            "SVM Average Precision (PR-AUC): 0.522561241453642\n",
            "SVM Binary Accuracy: 0.97\n",
            "SVM Top-1 accuracy: 0.5\n",
            "\n",
            "Predicted vs. True Champions by Season (SVM):\n",
            "   season team_pred  pred_prob  team_true  correct\n",
            "0    2016  Warriors   0.636980  Cavaliers        0\n",
            "1    2017  Warriors   0.533992   Warriors        1\n",
            "2    2018  Warriors   0.529117   Warriors        1\n",
            "3    2019   Raptors   0.497179    Raptors        1\n",
            "4    2020     Bucks   0.079158     Lakers        0\n",
            "5    2021  Clippers   0.258022      Bucks        0\n",
            "6    2022   Celtics   0.459285   Warriors        0\n",
            "7    2023   Celtics   0.260996    Nuggets        0\n",
            "8    2024   Celtics   0.548725    Celtics        1\n",
            "9    2025   Thunder   0.376435    Thunder        1\n",
            "\n",
            "Top-K Accuracy:\n",
            " Top-1: 0.5000\n",
            " Top-2: 0.9000\n",
            " Top-4: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "features_df = pd.read_csv(\"team_season_features_v2_clean-2.csv\")\n",
        "\n",
        "num_cols = features_df.select_dtypes(include=\"number\").columns.tolist() #remove features not to be used in training data\n",
        "for col in [\"champion\", \"season\"]:\n",
        "    if col in num_cols:\n",
        "        num_cols.remove(col)\n",
        "\n",
        "# add season-relative features (rank and z-score within each season)\n",
        "for col in num_cols:\n",
        "    features_df[f'{col}_season_rank'] = features_df.groupby('season')[col].rank(pct=True)\n",
        "    features_df[f'{col}_season_zscore'] = features_df.groupby('season')[col].transform(\n",
        "        lambda x: (x - x.mean()) / x.std() if x.std() > 0 else 0\n",
        "    )\n",
        "\n",
        "# update feature list\n",
        "num_cols_extended = features_df.select_dtypes(include=\"number\").columns.tolist()\n",
        "for col in [\"champion\", \"season\"]:\n",
        "    if col in num_cols_extended:\n",
        "        num_cols_extended.remove(col)\n",
        "\n",
        "X = features_df[num_cols_extended].copy()\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "y = features_df[\"champion\"].astype(int)\n",
        "\n",
        "#temporal split\n",
        "train_mask = features_df[\"season\"] <= 2015\n",
        "X_train, X_test = X[train_mask], X[~train_mask]\n",
        "y_train, y_test = y[train_mask], y[~train_mask]\n",
        "\n",
        "id_test = features_df.loc[~train_mask, [\"season\", \"team\", \"champion\"]].copy()\n",
        "\n",
        "svm_base = SVC(\n",
        "    kernel=\"rbf\",\n",
        "    C=6.5,\n",
        "    gamma=\"scale\",\n",
        "    class_weight=\"balanced\",\n",
        "    probability=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_cal = CalibratedClassifierCV(\n",
        "    svm_base,\n",
        "    method=\"sigmoid\",\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "svm_model = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scale\", StandardScaler(with_mean=True, with_std=True)),\n",
        "    (\"clf\", svm_cal),\n",
        "])\n",
        "\n",
        "# svm_model.fit(X_train, y_train)\n",
        "# svm_probs = svm_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "param_grid = {\n",
        "    \"clf__estimator__C\": [1, 3, 6, 10, 20],\n",
        "    \"clf__estimator__gamma\": [\"scale\", \"auto\", 0.1, 0.01],\n",
        "    \"clf__estimator__class_weight\": [None, \"balanced\"]\n",
        "}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    svm_model,\n",
        "    param_grid,\n",
        "    scoring=\"average_precision\",   # best for your ranking / top-1 goal\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "svm_best = grid.best_estimator_\n",
        "\n",
        "svm_probs = svm_best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"SVM ROC-AUC:\", roc_auc_score(y_test, svm_probs))\n",
        "print(\"SVM Average Precision (PR-AUC):\", average_precision_score(y_test, svm_probs))\n",
        "\n",
        "svm_pred_labels = (svm_probs > 0.5).astype(int)\n",
        "print(\"SVM Binary Accuracy:\", accuracy_score(y_test, svm_pred_labels))\n",
        "\n",
        "id_test[\"svm_proba_win\"] = svm_probs\n",
        "\n",
        "id_test[\"ranking_score\"] = id_test[\"svm_proba_win\"]\n",
        "id_test[\"rank\"] = (\n",
        "    id_test.groupby(\"season\")[\"ranking_score\"]\n",
        "           .rank(ascending=False, method=\"first\")\n",
        ")\n",
        "\n",
        "idx = id_test.groupby(\"season\")[\"svm_proba_win\"].idxmax()\n",
        "\n",
        "svm_predicted_champs = (\n",
        "    id_test.loc[idx, [\"season\", \"team\", \"svm_proba_win\"]]\n",
        "           .rename(columns={\"team\": \"team_pred\", \"svm_proba_win\": \"pred_prob\"})\n",
        "           .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "true_champs = (\n",
        "    id_test.loc[id_test[\"champion\"] == 1, [\"season\", \"team\"]]\n",
        "           .rename(columns={\"team\": \"team_true\"})\n",
        "           .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "svm_eval = svm_predicted_champs.merge(true_champs, on=\"season\", how=\"left\")\n",
        "svm_eval[\"correct\"] = (svm_eval[\"team_pred\"] == svm_eval[\"team_true\"]).astype(int)\n",
        "\n",
        "print(\"SVM Top-1 accuracy:\", svm_eval[\"correct\"].mean())\n",
        "print(\"\\nPredicted vs. True Champions by Season (SVM):\")\n",
        "print(svm_eval.sort_values(\"season\"))\n",
        "\n",
        "# ranks of the true champions in their seasons\n",
        "true_champ_ranks = id_test.loc[id_test[\"champion\"] == 1, \"rank\"]\n",
        "\n",
        "# print top-k accuracies\n",
        "k_values = [1, 2, 4]   # or whatever kâ€™s you care about\n",
        "print(\"\\nTop-K Accuracy:\")\n",
        "for k in k_values:\n",
        "    accuracy = (true_champ_ranks <= k).mean()\n",
        "    print(f\" Top-{k}: {accuracy:.4f}\")"
      ]
    }
  ]
}