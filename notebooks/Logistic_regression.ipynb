{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJrrtmei2xuADWio5jZbYJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patsoong/CS506FinalProject/blob/main/notebooks/Logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hsvheP2nMNBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adec9dc9-9179-4cf7-e12c-47c0ad52b786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 0.9627586206896551\n",
            "Average Precision (PR-AUC): 0.5511730032419687\n",
            "Binary accuracy: 0.9666666666666667\n",
            "Top-1 accuracy: 0.8\n",
            "\n",
            "Predicted vs. True Champions by Season:\n",
            "\n",
            " season team_pred team_true  pred_prob  correct\n",
            "   2016  Warriors Cavaliers   0.994014        0\n",
            "   2017  Warriors  Warriors   0.994092        1\n",
            "   2018  Warriors  Warriors   0.815186        1\n",
            "   2019   Raptors   Raptors   0.182558        1\n",
            "   2020    Lakers    Lakers   0.007219        1\n",
            "   2021      Suns     Bucks   0.075588        0\n",
            "   2022  Warriors  Warriors   0.078105        1\n",
            "   2023   Nuggets   Nuggets   0.048625        1\n",
            "   2024   Celtics   Celtics   0.823239        1\n",
            "   2025   Thunder   Thunder   0.839275        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "features_df = pd.read_csv(\"team_season_features_v2_clean-2.csv\")\n",
        "\n",
        "num_cols = features_df.select_dtypes(include=\"number\").columns.tolist() #remove features not to be used in training data\n",
        "for col in [\"champion\", \"season\"]:\n",
        "    if col in num_cols:\n",
        "        num_cols.remove(col)\n",
        "\n",
        "X = features_df[num_cols].copy()\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "y = features_df[\"champion\"].astype(int)\n",
        "\n",
        "#temporal split\n",
        "train_mask = features_df[\"season\"] <= 2015\n",
        "X_train, X_test = X[train_mask], X[~train_mask]\n",
        "y_train, y_test = y[train_mask], y[~train_mask]\n",
        "\n",
        "id_test = features_df.loc[~train_mask, [\"season\", \"team\", \"champion\"]].copy()\n",
        "\n",
        "model = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n",
        "    (\"scale\", StandardScaler(with_mean=True, with_std=True)),\n",
        "    (\"clf\", LogisticRegression(\n",
        "        multi_class='ovr',\n",
        "        class_weight='balanced',\n",
        "        max_iter=10000,\n",
        "        C=1,\n",
        "        random_state=42\n",
        "        ))\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "probabilities = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# measures how well your model can rank positive examples (champions) above\n",
        "# negatives (non-champions), across all possible probability thresholds\n",
        "# ROC-AUC = probability that your model assigns a higher predicted probability to the champion\n",
        "# How well does the model rank real champions higher than others?\n",
        "# how well it ranks teams overall\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, probabilities))\n",
        "\n",
        "# emphasizes performance on the positive class\n",
        "# How well does the model focus on the true champion cases out of all possible teams?\n",
        "# how good it is at finding the actual champions\n",
        "print(\"Average Precision (PR-AUC):\", average_precision_score(y_test, probabilities))\n",
        "\n",
        "pred_labels = (probabilities > 0.5).astype(int)\n",
        "print(\"Binary accuracy:\", accuracy_score(y_test, pred_labels))\n",
        "\n",
        "id_test[\"proba_win\"] = probabilities\n",
        "\n",
        "idx = id_test.groupby(\"season\")[\"proba_win\"].idxmax()\n",
        "\n",
        "predicted_champs = (\n",
        "    id_test.loc[idx, [\"season\", \"team\", \"proba_win\"]]\n",
        "           .rename(columns={\"team\": \"team_pred\", \"proba_win\": \"pred_prob\"})\n",
        "           .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "true_champs = (\n",
        "    id_test.loc[id_test[\"champion\"] == 1, [\"season\", \"team\"]]\n",
        "           .rename(columns={\"team\": \"team_true\"})\n",
        "           .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "eval = predicted_champs.merge(true_champs, on=\"season\", suffixes=(\"_pred\", \"_true\"))\n",
        "eval[\"correct\"] = (eval[\"team_pred\"] == eval[\"team_true\"]).astype(int)\n",
        "print(\"Top-1 accuracy:\", eval[\"correct\"].mean())\n",
        "\n",
        "print(\"\\nPredicted vs. True Champions by Season:\\n\")\n",
        "print(eval[[\"season\", \"team_pred\", \"team_true\", \"pred_prob\", \"correct\"]]\n",
        "      .sort_values(\"season\")\n",
        "      .to_string(index=False))"
      ]
    }
  ]
}