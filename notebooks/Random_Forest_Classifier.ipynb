{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtshyh3WoOAEt9hl3+Vu6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patsoong/CS506FinalProject/blob/main/notebooks/Random_Forest_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_zxrlkLWoy",
        "outputId": "e1d8f92d-e9b2-426d-9e15-95a06bd1ae6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF ROC-AUC: 0.9879310344827587\n",
            "RF Average Precision (PR-AUC): 0.8336494252873563\n",
            "RF Binary Accuracy: 0.9833333333333333\n",
            "RF Top-1 accuracy: 0.7\n",
            "Predicted vs. True Champions by Season:\n",
            "   season team_pred  pred_prob  team_true  correct\n",
            "0    2016  Warriors   0.521217  Cavaliers        0\n",
            "1    2017  Warriors   0.739682   Warriors        1\n",
            "2    2018  Warriors   0.483521   Warriors        1\n",
            "3    2019   Raptors   0.841025    Raptors        1\n",
            "4    2020     Bucks   0.078294     Lakers        0\n",
            "5    2021  Clippers   0.043562      Bucks        0\n",
            "6    2022  Warriors   0.710242   Warriors        1\n",
            "7    2023   Nuggets   0.760820    Nuggets        1\n",
            "8    2024   Celtics   0.899829    Celtics        1\n",
            "9    2025   Thunder   0.841519    Thunder        1\n",
            "\n",
            "Top-K Accuracy:\n",
            " Top-1: 0.7000\n",
            " Top-2: 1.0000\n",
            " Top-4: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "features_df = pd.read_csv(\"team_season_features_v2_clean-2.csv\")\n",
        "\n",
        "#remove features not to be used in training data\n",
        "num_cols = features_df.select_dtypes(include=\"number\").columns.tolist()\n",
        "for col in [\"champion\", \"season\"]:\n",
        "    if col in num_cols:\n",
        "        num_cols.remove(col)\n",
        "\n",
        "# add season-relative features (rank and z-score within each season)\n",
        "for col in num_cols:\n",
        "    features_df[f'{col}_season_rank'] = features_df.groupby('season')[col].rank(pct=True)\n",
        "    features_df[f'{col}_season_zscore'] = features_df.groupby('season')[col].transform(\n",
        "        lambda x: (x - x.mean()) / x.std() if x.std() > 0 else 0\n",
        "    )\n",
        "\n",
        "# update feature list\n",
        "num_cols_extended = features_df.select_dtypes(include=\"number\").columns.tolist()\n",
        "for col in [\"champion\", \"season\"]:\n",
        "    if col in num_cols_extended:\n",
        "        num_cols_extended.remove(col)\n",
        "\n",
        "X = features_df[num_cols_extended].copy()\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "y = features_df[\"champion\"].astype(int)\n",
        "\n",
        "#temporal split\n",
        "train_mask = features_df[\"season\"] <= 2015\n",
        "X_train, X_test = X[train_mask], X[~train_mask]\n",
        "y_train, y_test = y[train_mask], y[~train_mask]\n",
        "\n",
        "id_test = features_df.loc[~train_mask, [\"season\", \"team\", \"champion\"]].copy()\n",
        "\n",
        "base_rf = RandomForestClassifier(\n",
        "        n_estimators=5000,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1,\n",
        "        bootstrap=True,\n",
        "        max_features='sqrt',\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "rf_cal = CalibratedClassifierCV(base_rf, method=\"sigmoid\", cv=3)\n",
        "\n",
        "rf_model = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"clf\", rf_cal),\n",
        "])\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"RF ROC-AUC:\", roc_auc_score(y_test, rf_probs))\n",
        "print(\"RF Average Precision (PR-AUC):\", average_precision_score(y_test, rf_probs))\n",
        "\n",
        "rf_pred_labels = (rf_probs > 0.5).astype(int)\n",
        "print(\"RF Binary Accuracy:\", accuracy_score(y_test, rf_pred_labels))\n",
        "\n",
        "id_test[\"rf_proba_win\"] = rf_probs\n",
        "id_test[\"ranking_score\"] = id_test[\"rf_proba_win\"]\n",
        "id_test[\"rank\"] = (\n",
        "    id_test.groupby(\"season\")[\"ranking_score\"]\n",
        "           .rank(ascending=False, method=\"first\")\n",
        ")\n",
        "\n",
        "idx = id_test.groupby(\"season\")[\"rf_proba_win\"].idxmax()\n",
        "\n",
        "rf_predicted_champs = (\n",
        "    id_test.loc[idx, [\"season\", \"team\", \"rf_proba_win\"]]\n",
        "           .rename(columns={\"team\": \"team_pred\", \"rf_proba_win\": \"pred_prob\"})\n",
        "           .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "rf_true_champs = (\n",
        "    id_test.loc[id_test[\"champion\"] == 1, [\"season\", \"team\"]]\n",
        "           .rename(columns={\"team\": \"team_true\"})\n",
        "           .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "rf_eval = rf_predicted_champs.merge(rf_true_champs, on=\"season\", how=\"left\")\n",
        "rf_eval[\"correct\"] = (rf_eval[\"team_pred\"] == rf_eval[\"team_true\"]).astype(int)\n",
        "\n",
        "print(\"RF Top-1 accuracy:\", rf_eval[\"correct\"].mean())\n",
        "print(\"Predicted vs. True Champions by Season:\")\n",
        "print(rf_eval)\n",
        "\n",
        "true_champ_ranks = id_test.loc[id_test[\"champion\"] == 1, \"rank\"]\n",
        "\n",
        "# print top-k accuracies\n",
        "k_values = [1, 2, 4]\n",
        "print(\"\\nTop-K Accuracy:\")\n",
        "for k in k_values:\n",
        "    accuracy = (true_champ_ranks <= k).mean()\n",
        "    print(f\" Top-{k}: {accuracy:.4f}\")"
      ]
    }
  ]
}